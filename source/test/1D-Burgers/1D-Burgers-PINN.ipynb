{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0275341-ad74-4af1-bcd5-b189db22d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Networks import MLP\n",
    "from Trainers import Burges_1D_Trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79406ac-697c-4519-9c87-040dca2feb13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "input_shape = (1,)  # 输入形状\n",
    "output_shape = (1,)\n",
    "\n",
    "model = MLP(input_shape, output_shape, hidden_layers=[64, 64, 64, 64, 64, 64, 64], activation_function=\"tanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a263d72-94b1-4372-855c-71528f2e046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 1\n",
    "alpha = 1 \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "trainer = Burges_1D_Trainer(model, u, alpha, optimizer, lambda_pde=1e-3, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd32f793-6fb4-4bd0-82ee-d781e56912d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造 collocation 点（用于计算 PDE 残差）\n",
    "N_collocation = 1000\n",
    "# 在区间 [0, 1] 上均匀采样\n",
    "x_collocation = torch.linspace(0, 1, N_collocation).view(-1, 1)\n",
    "\n",
    "# 定义边界点和边界条件（这里假设 phi(0)=0, phi(1)=e，可根据问题实际设置）\n",
    "x_boundary = torch.tensor([[0.0], [1.0]])\n",
    "phi_boundary = torch.tensor([[1.0], [np.e]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eebd6a50-3553-4526-be8a-14c633e22722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c060b46dad6147c69bbe7de26062a422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000, Total Loss: 1.3420e-01 | PDE Loss: 1.2607e+02 | BC Loss: 8.1239e-03\n",
      "Epoch 101/5000, Total Loss: 5.9438e-03 | PDE Loss: 5.7933e+00 | BC Loss: 1.5042e-04\n",
      "Epoch 201/5000, Total Loss: 2.7787e-03 | PDE Loss: 2.7212e+00 | BC Loss: 5.7550e-05\n",
      "Epoch 301/5000, Total Loss: 9.0893e-04 | PDE Loss: 8.9528e-01 | BC Loss: 1.3648e-05\n",
      "Epoch 401/5000, Total Loss: 4.4776e-04 | PDE Loss: 4.0811e-01 | BC Loss: 3.9647e-05\n",
      "Epoch 501/5000, Total Loss: 2.2389e-04 | PDE Loss: 2.2298e-01 | BC Loss: 9.0425e-07\n",
      "Epoch 601/5000, Total Loss: 1.1936e-03 | PDE Loss: 1.5831e-01 | BC Loss: 1.0353e-03\n",
      "Epoch 701/5000, Total Loss: 1.0869e-04 | PDE Loss: 1.0823e-01 | BC Loss: 4.6330e-07\n",
      "Epoch 801/5000, Total Loss: 5.9636e-05 | PDE Loss: 5.9510e-02 | BC Loss: 1.2675e-07\n",
      "Epoch 901/5000, Total Loss: 3.8194e-05 | PDE Loss: 3.2241e-02 | BC Loss: 5.9531e-06\n",
      "Epoch 1001/5000, Total Loss: 4.0736e-05 | PDE Loss: 4.0028e-02 | BC Loss: 7.0783e-07\n",
      "Epoch 1101/5000, Total Loss: 2.1596e-05 | PDE Loss: 2.1561e-02 | BC Loss: 3.5039e-08\n",
      "Epoch 1201/5000, Total Loss: 1.3049e-05 | PDE Loss: 1.3033e-02 | BC Loss: 1.5827e-08\n",
      "Epoch 1301/5000, Total Loss: 1.0567e-03 | PDE Loss: 2.1626e-02 | BC Loss: 1.0351e-03\n",
      "Epoch 1401/5000, Total Loss: 1.7226e-05 | PDE Loss: 1.7128e-02 | BC Loss: 9.8006e-08\n",
      "Epoch 1501/5000, Total Loss: 1.1079e-05 | PDE Loss: 1.1067e-02 | BC Loss: 1.1517e-08\n",
      "Epoch 1601/5000, Total Loss: 8.4127e-06 | PDE Loss: 8.4066e-03 | BC Loss: 6.1149e-09\n",
      "Epoch 1701/5000, Total Loss: 4.0000e-05 | PDE Loss: 7.0579e-03 | BC Loss: 3.2942e-05\n",
      "Epoch 1801/5000, Total Loss: 1.5389e-05 | PDE Loss: 1.5209e-02 | BC Loss: 1.7932e-07\n",
      "Epoch 1901/5000, Total Loss: 9.8014e-06 | PDE Loss: 9.7926e-03 | BC Loss: 8.7517e-09\n",
      "Epoch 2001/5000, Total Loss: 7.5404e-06 | PDE Loss: 7.5360e-03 | BC Loss: 4.4398e-09\n",
      "Epoch 2101/5000, Total Loss: 6.2018e-06 | PDE Loss: 6.1991e-03 | BC Loss: 2.6893e-09\n",
      "Epoch 2201/5000, Total Loss: 1.8166e-05 | PDE Loss: 1.6149e-02 | BC Loss: 2.0169e-06\n",
      "Epoch 2301/5000, Total Loss: 9.2272e-06 | PDE Loss: 9.2196e-03 | BC Loss: 7.5410e-09\n",
      "Epoch 2401/5000, Total Loss: 6.8111e-06 | PDE Loss: 6.8074e-03 | BC Loss: 3.7000e-09\n",
      "Epoch 2501/5000, Total Loss: 5.4607e-06 | PDE Loss: 5.4586e-03 | BC Loss: 2.1614e-09\n",
      "Epoch 2601/5000, Total Loss: 3.3946e-04 | PDE Loss: 2.0771e-02 | BC Loss: 3.1869e-04\n",
      "Epoch 2701/5000, Total Loss: 9.9826e-06 | PDE Loss: 9.9722e-03 | BC Loss: 1.0429e-08\n",
      "Epoch 2801/5000, Total Loss: 6.7306e-06 | PDE Loss: 6.7269e-03 | BC Loss: 3.7498e-09\n",
      "Epoch 2901/5000, Total Loss: 5.1818e-06 | PDE Loss: 5.1798e-03 | BC Loss: 2.0326e-09\n",
      "Epoch 3001/5000, Total Loss: 4.2522e-06 | PDE Loss: 4.2510e-03 | BC Loss: 1.2288e-09\n",
      "Epoch 3101/5000, Total Loss: 2.4233e-05 | PDE Loss: 1.3625e-02 | BC Loss: 1.0608e-05\n",
      "Epoch 3201/5000, Total Loss: 7.1151e-06 | PDE Loss: 7.1099e-03 | BC Loss: 5.2233e-09\n",
      "Epoch 3301/5000, Total Loss: 5.1935e-06 | PDE Loss: 5.1916e-03 | BC Loss: 1.9046e-09\n",
      "Epoch 3401/5000, Total Loss: 4.2179e-06 | PDE Loss: 4.2167e-03 | BC Loss: 1.1587e-09\n",
      "Epoch 3501/5000, Total Loss: 1.0284e-04 | PDE Loss: 1.8408e-02 | BC Loss: 8.4437e-05\n",
      "Epoch 3601/5000, Total Loss: 8.1048e-06 | PDE Loss: 8.0906e-03 | BC Loss: 1.4176e-08\n",
      "Epoch 3701/5000, Total Loss: 5.4763e-06 | PDE Loss: 5.4744e-03 | BC Loss: 1.8829e-09\n",
      "Epoch 3801/5000, Total Loss: 4.3696e-06 | PDE Loss: 4.3686e-03 | BC Loss: 9.5466e-10\n",
      "Epoch 3901/5000, Total Loss: 2.6765e-05 | PDE Loss: 3.6557e-03 | BC Loss: 2.3110e-05\n",
      "Epoch 4001/5000, Total Loss: 9.8097e-06 | PDE Loss: 9.5681e-03 | BC Loss: 2.4161e-07\n",
      "Epoch 4101/5000, Total Loss: 5.5524e-06 | PDE Loss: 5.5506e-03 | BC Loss: 1.7492e-09\n",
      "Epoch 4201/5000, Total Loss: 4.2365e-06 | PDE Loss: 4.2356e-03 | BC Loss: 8.2745e-10\n",
      "Epoch 4301/5000, Total Loss: 5.5926e-06 | PDE Loss: 3.4601e-03 | BC Loss: 2.1325e-06\n",
      "Epoch 4401/5000, Total Loss: 9.7741e-06 | PDE Loss: 9.5477e-03 | BC Loss: 2.2638e-07\n",
      "Epoch 4501/5000, Total Loss: 5.0606e-06 | PDE Loss: 5.0592e-03 | BC Loss: 1.3938e-09\n",
      "Epoch 4601/5000, Total Loss: 3.6590e-06 | PDE Loss: 3.6583e-03 | BC Loss: 6.8601e-10\n",
      "Epoch 4701/5000, Total Loss: 2.8559e-06 | PDE Loss: 2.7842e-03 | BC Loss: 7.1643e-08\n",
      "Epoch 4801/5000, Total Loss: 8.5134e-06 | PDE Loss: 7.4528e-03 | BC Loss: 1.0605e-06\n",
      "Epoch 4901/5000, Total Loss: 3.7011e-06 | PDE Loss: 3.7002e-03 | BC Loss: 8.3765e-10\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "trainer.train(x_collocation, x_boundary, phi_boundary, epochs=5000, save_path='pinntest.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ddc1b47-0320-4f56-a10d-87eb401844dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8601f70b05ae40e2a7ceafd614b5b32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000, Total Loss: 6.7590e-02 | PDE Loss: 4.6891e+01 | BC Loss: 6.7586e-02\n",
      "Epoch 101/3000, Total Loss: 6.7216e-06 | PDE Loss: 6.3077e+01 | BC Loss: 4.1396e-07\n",
      "Epoch 201/3000, Total Loss: 6.2952e-06 | PDE Loss: 6.2951e+01 | BC Loss: 1.3065e-10\n",
      "Epoch 301/3000, Total Loss: 6.2856e-06 | PDE Loss: 6.2856e+01 | BC Loss: 7.1992e-11\n",
      "Epoch 401/3000, Total Loss: 6.2740e-06 | PDE Loss: 6.2740e+01 | BC Loss: 7.5211e-11\n",
      "Epoch 501/3000, Total Loss: 6.2606e-06 | PDE Loss: 6.2605e+01 | BC Loss: 7.0997e-11\n",
      "Epoch 601/3000, Total Loss: 6.2454e-06 | PDE Loss: 6.2453e+01 | BC Loss: 7.2511e-11\n",
      "Epoch 701/3000, Total Loss: 6.2285e-06 | PDE Loss: 6.2284e+01 | BC Loss: 7.1488e-11\n",
      "Epoch 801/3000, Total Loss: 6.2100e-06 | PDE Loss: 6.2099e+01 | BC Loss: 7.2511e-11\n",
      "Epoch 901/3000, Total Loss: 6.1898e-06 | PDE Loss: 6.1897e+01 | BC Loss: 7.0401e-11\n",
      "Epoch 1001/3000, Total Loss: 6.1681e-06 | PDE Loss: 6.1680e+01 | BC Loss: 6.9349e-11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Burges_1D_Trainer(model, u, alpha, optimizer, lambda_pde\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_collocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_boundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_boundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpinntest.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonPrograms/PIRN/source/Trainers/Trainer.py:311\u001b[0m, in \u001b[0;36mBurges_1D_Trainer.train\u001b[0;34m(self, collocation_points, boundary_points, boundary_values, epochs, save_path)\u001b[0m\n\u001b[1;32m    309\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_pde \u001b[38;5;241m*\u001b[39m pde_loss \u001b[38;5;241m+\u001b[39m bc_loss\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m--> 311\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m best_loss:\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter_env/lib/python3.9/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter_env/lib/python3.9/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter_env/lib/python3.9/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "trainer = Burges_1D_Trainer(model, u, alpha, optimizer, lambda_pde=1e-7, device='cuda')\n",
    "trainer.train(x_collocation, x_boundary, phi_boundary, epochs=3000, save_path='pinntest.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5e4ec-2a0c-4ef0-830b-8ae3b315a4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
